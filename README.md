# ğŸ® Rock Paper Scissors IA

Un jeu de Pierre-Feuille-Ciseau intelligent utilisant la vision par ordinateur pour dÃ©tecter les gestes de la main en temps rÃ©el.

![Screenshot du jeu](assets/20250621_2025_Pierre%20Feuille%20Ciseau%20IA_simple_compose_01jy9vq9yzfgxt5qbadzbvtmff.png)

## ğŸ¯ FonctionnalitÃ©s

- **DÃ©tection de gestes en temps rÃ©el** : Utilise MediaPipe pour reconnaÃ®tre les gestes Pierre, Feuille, Ciseau
- **Intelligence artificielle** : IA adversaire avec sÃ©lection alÃ©atoire des coups
- **Interface moderne** : Frontend React TypeScript avec capture webcam
- **API REST** : Backend FastAPI pour les prÃ©dictions de gestes
- **Collecte de donnÃ©es** : Interface Streamlit pour entraÃ®ner le modÃ¨le
- **Machine Learning** : RÃ©seau de neurones TensorFlow pour la classification

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10
- Node.js 16+
- npm ou yarn
- Webcam fonctionnelle
- Docker

## ğŸ® Utilisation

### 1. Collecte de donnÃ©es

Pour amÃ©liorer le modÃ¨le avec vos propres donnÃ©es :

```powershell
# Lancer l'interface de collecte
cd training
.\run_collect_data.bat
```

- SÃ©lectionnez le geste Ã  enregistrer (pierre, feuille, ciseau)
- Montrez votre geste devant la webcam
- Cliquez sur "Enregistrer" pour sauvegarder

### 2. EntraÃ®nement du modÃ¨le

```powershell
# EntraÃ®ner le modÃ¨le avec les nouvelles donnÃ©es
cd training
python train_model.py
```

### 3. Visualisation du model

```powershell
cd models
.\run_test_model.bat
```

### 4. Lancement de l'application 

```bash
cd app
./build-all.sh
docker compose up
```

## ğŸ² Comment jouer

1. **Autoriser l'accÃ¨s webcam** : Le navigateur vous demandera l'autorisation
2. **Placer votre main** : Montrez votre geste devant la camÃ©ra
3. **Cliquer sur GO** : L'IA choisira son geste alÃ©atoirement
4. **Voir le rÃ©sultat** : Le gagnant sera affichÃ© selon les rÃ¨gles classiques :
   - ğŸª¨ Pierre bat âœ‚ï¸ Ciseau
   - ğŸ“„ Feuille bat ğŸª¨ Pierre  
   - âœ‚ï¸ Ciseau bat ğŸ“„ Feuille

## ğŸ¤– Fonctionnement technique

### Pipeline de dÃ©tection
1. **Capture vidÃ©o** : La webcam capture les images en temps rÃ©el
2. **Extraction de landmarks** : MediaPipe dÃ©tecte 21 points clÃ©s de la main
3. **Vectorisation** : Les coordonnÃ©es (x,y,z) sont converties en vecteur de 63 dimensions
4. **PrÃ©diction** : Le rÃ©seau de neurones classifie le geste
5. **Affichage** : Le rÃ©sultat est affichÃ© dans l'interface

### ModÃ¨le de Machine Learning
- **Architecture** : RÃ©seau dense (1024â†’1024â†’1024â†’3 neurones)
- **EntrÃ©e** : 63 features (21 landmarks Ã— 3 coordonnÃ©es)
- **Sortie** : ProbabilitÃ©s pour 3 classes (pierre, feuille, ciseau)
- **Framework** : TensorFlow/Keras
- **RÃ©gularisation** : Dropout (30%) et BatchNormalization

## ğŸ“Š DonnÃ©es d'entraÃ®nement

Le modÃ¨le est entraÃ®nÃ© sur :
- **Format** : Fichiers CSV avec coordonnÃ©es des landmarks
- **Classes** : pierre, feuille, ciseau
- **Division** : 80% entraÃ®nement / 20% validation
- **Augmentation** : Collecte interactive via Streamlit


## ğŸ”§ DÃ©veloppement

### Structure des API

**Backend (port 8000)**
- `POST /predict` : Upload d'image pour prÃ©diction de geste
  - Input : multipart/form-data avec fichier image
  - Output : `{"gesture": "pierre|feuille|ciseau"}`

â­ **N'oubliez pas de mettre une Ã©toile si ce projet vous a plu !** â­
