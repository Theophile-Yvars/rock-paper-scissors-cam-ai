# ğŸ® Rock Paper Scissors IA

Un jeu de Pierre-Feuille-Ciseau intelligent utilisant la vision par ordinateur pour dÃ©tecter les gestes de la main en temps rÃ©el.

![Screenshot du jeu](assets/20250621_2025_Pierre%20Feuille%20Ciseau%20IA_simple_compose_01jy9vq9yzfgxt5qbadzbvtmff.png)

## ğŸ¯ FonctionnalitÃ©s

- **DÃ©tection de gestes en temps rÃ©el** : Utilise MediaPipe pour reconnaÃ®tre les gestes Pierre, Feuille, Ciseau
- **Intelligence artificielle** : IA adversaire avec sÃ©lection alÃ©atoire des coups
- **Interface moderne** : Frontend React TypeScript avec capture webcam
- **API REST** : Backend FastAPI pour les prÃ©dictions de gestes
- **Collecte de donnÃ©es** : Interface Streamlit pour entraÃ®ner le modÃ¨le
- **Machine Learning** : RÃ©seau de neurones TensorFlow pour la classification

## ğŸ—ï¸ Architecture

Le projet est structurÃ© en plusieurs composants :

```
rock-paper-scissors-cam-ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ backend/          # API FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py       # Serveur API
â”‚   â”‚   â””â”€â”€ classifier.py # Classification des gestes
â”‚   â””â”€â”€ frontend/         # Interface React
â”‚       â””â”€â”€ src/
â”œâ”€â”€ training/             # EntraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ collect_data.py   # Collecte de donnÃ©es
â”‚   â””â”€â”€ train_model.py    # EntraÃ®nement
â”œâ”€â”€ models/               # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ data/                 # DonnÃ©es d'entraÃ®nement
â””â”€â”€ assets/              # Ressources multimÃ©dia
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- Node.js 16+
- npm ou yarn
- Webcam fonctionnelle

### Installation des dÃ©pendances

#### Backend Python
```powershell
# Installer les dÃ©pendances Python
pip install -r requirements.txt
```

#### Frontend React
```powershell
# Naviguer vers le frontend
cd app/frontend

# Installer les dÃ©pendances Node.js
npm install
```

## ğŸ® Utilisation

### 1. Collecte de donnÃ©es (optionnel)

Pour amÃ©liorer le modÃ¨le avec vos propres donnÃ©es :

```powershell
# Lancer l'interface de collecte
cd training
streamlit run collect_data.py
```

- SÃ©lectionnez le geste Ã  enregistrer (pierre, feuille, ciseau)
- Montrez votre geste devant la webcam
- Cliquez sur "Enregistrer" pour sauvegarder

### 2. EntraÃ®nement du modÃ¨le (optionnel)

```powershell
# EntraÃ®ner le modÃ¨le avec les nouvelles donnÃ©es
cd training
python train_model.py
```

### 3. Lancement de l'application

#### DÃ©marrer le backend
```powershell
# Terminal 1 : API Backend
cd app/backend
uvicorn main:app --reload
```
L'API sera disponible sur `http://localhost:8000`

#### DÃ©marrer le frontend
```powershell
# Terminal 2 : Interface utilisateur
cd app/frontend
npm start
```
L'application sera disponible sur `http://localhost:3000`

## ğŸ² Comment jouer

1. **Autoriser l'accÃ¨s webcam** : Le navigateur vous demandera l'autorisation
2. **Placer votre main** : Montrez votre geste devant la camÃ©ra
3. **Cliquer sur GO** : L'IA choisira son geste alÃ©atoirement
4. **Voir le rÃ©sultat** : Le gagnant sera affichÃ© selon les rÃ¨gles classiques :
   - ğŸª¨ Pierre bat âœ‚ï¸ Ciseau
   - ğŸ“„ Feuille bat ğŸª¨ Pierre  
   - âœ‚ï¸ Ciseau bat ğŸ“„ Feuille

## ğŸ¤– Fonctionnement technique

### Pipeline de dÃ©tection
1. **Capture vidÃ©o** : La webcam capture les images en temps rÃ©el
2. **Extraction de landmarks** : MediaPipe dÃ©tecte 21 points clÃ©s de la main
3. **Vectorisation** : Les coordonnÃ©es (x,y,z) sont converties en vecteur de 63 dimensions
4. **PrÃ©diction** : Le rÃ©seau de neurones classifie le geste
5. **Affichage** : Le rÃ©sultat est affichÃ© dans l'interface

### ModÃ¨le de Machine Learning
- **Architecture** : RÃ©seau dense (1024â†’1024â†’1024â†’3 neurones)
- **EntrÃ©e** : 63 features (21 landmarks Ã— 3 coordonnÃ©es)
- **Sortie** : ProbabilitÃ©s pour 3 classes (pierre, feuille, ciseau)
- **Framework** : TensorFlow/Keras
- **RÃ©gularisation** : Dropout (30%) et BatchNormalization

## ğŸ“Š DonnÃ©es d'entraÃ®nement

Le modÃ¨le est entraÃ®nÃ© sur :
- **Format** : Fichiers CSV avec coordonnÃ©es des landmarks
- **Classes** : pierre, feuille, ciseau
- **Division** : 80% entraÃ®nement / 20% validation
- **Augmentation** : Collecte interactive via Streamlit

## ğŸ› ï¸ Technologies utilisÃ©es

| Composant | Technologie |
|-----------|-------------|
| **Vision** | MediaPipe |
| **IA** | TensorFlow, Keras |
| **Backend** | FastAPI, uvicorn |
| **Frontend** | React 19, TypeScript |
| **Collecte** | Streamlit |
| **Processing** | OpenCV, NumPy |
| **Data Science** | scikit-learn, pandas |

## ğŸ”§ DÃ©veloppement

### Structure des API

**Backend (port 8000)**
- `POST /predict` : Upload d'image pour prÃ©diction de geste
  - Input : multipart/form-data avec fichier image
  - Output : `{"gesture": "pierre|feuille|ciseau"}`

### Scripts utiles

```powershell
# Tests du modÃ¨le
cd models
python test_model.py

# Build frontend pour production
cd app/frontend
npm run build

# Lancer les tests frontend
npm test
```

## ğŸ“ AmÃ©liorations possibles

- [ ] Multijoueur en ligne
- [ ] Historique des parties
- [ ] Statistiques de performance
- [ ] AmÃ©lioration de la prÃ©cision du modÃ¨le
- [ ] Support multi-langues
- [ ] Mode tournoi
- [ ] Gestes personnalisÃ©s

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“„ License

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ“ Contact

Si vous avez des questions ou suggestions, n'hÃ©sitez pas Ã  ouvrir une issue ou me contacter.

---

â­ **N'oubliez pas de mettre une Ã©toile si ce projet vous a plu !** â­
